\documentclass[11pt,a4paper,notitlepage]{scrreprt}
\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{ulsy}
\usepackage{tikz}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amsmath,amssymb,amstext,amsfonts,mathrsfs, amsthm}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{color}
\usepackage{enumitem}
\usepackage{framed}


% Mathmatische Symbole
\newcommand{\RR}{\mathbb{R}}
\newcommand{\EE}{\mathbb{E}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\FF}{\mathcal{F}}
\newcommand{\supp}{\operatorname{supp}}
\newcommand{\ee}{\operatorname{e}}
\newcommand{\dist}{\operatorname{dist}}
\newcommand{\grad}{\operatorname{grad}}

\newtheorem{defi}{Definition}[section]
\newtheorem{prop}[defi]{Proposition}
\newtheorem{theorem}[defi]{Theorem}
\newtheorem{cor}[defi]{Corollar}
\newtheorem{lem}[defi]{Lemma}
\newtheorem{bem}[defi]{Bemerkung}

\author{ich}
\title{Seminar 0.0}



\begin{document}
\parindent 0pt


%\maketitle
%\newpage
%\tableofcontents
%\newpage

\pagestyle{plain}



 Prof. Dr. Matthes \hfill Manuela Lambacher\\
 Optimaler Transport - Geometrie und Anwendungen \hfill xx.12.2015
 \begin{center}
  {\huge{tolles referat}} 
 \end{center}
 
 \hrule
 
\numberwithin{equation}{section}
\renewcommand{\thechapter}{\arabic{section}}
\renewcommand{\thesection}{\arabic{section}}
\section{Generalisierte Gradientenflüsse}

Wir betrachten folgende partielle Diffgleichung: 
\begin{eqnarray}
\dfrac{dX}{dt}=~-\grad E(X) \label{eq1}
\end{eqnarray}
$E$ ist hierbei die Energie im Bezug auf den Optimalen Transport, die Diffgl beschreibt z.b. die kinetische Energie von Partikeln. 
TODO: Räume, was woraus... 
\newline

Um dieses Problem nicht explizit zu lösen, wollen wir es zeitlich diskretisieren, sodann zum Limes übergehen während unser Zeitschritt gegen Null geht. Dabei können subdifferentiale und tangentenräume schön umgangen werden und der GradientenOperator nicht explizit benutzt werden.

\begin{defi}
Der approximierte Gradientenfluss für ein Energie-Funktional E in einem abstraktem Metrischen Raum mit einer metric-denoted Distanz sei gegeben durch:
\newline
Sei der timestep $\tau > 0$, dann ist die Folge $\left( X^n_\tau \right)_{n\geq 0}$:
\\
$X_\tau^0:=X_0,$
\\
$X_\tau^{n+1}$ ist der Minimierer (oder ein Minimierer, wir verlangen keine Eindeutigkeit TODO: ex eine lösung?) von 
\begin{eqnarray}
\min\left[E(X)+\dfrac{\dist(X_\tau^n,X)^2}{2\tau}\right] \label{Min}
\end{eqnarray}
Sei $X_\tau$ auf $\RR_+$ als stückweise konstante Funktion mit Wert $X_\tau(t)=X^n_\tau$ für $t\in [n\tau,(n+1)\tau)$.
\end{defi}

\begin{bem}
Betrachtet man den euklidischen Abstand, ist die Euler-Lagrange-Gleichung zu dem Minimierungsproblem (\ref{Min})
\begin{eqnarray*}
\dfrac{X_\tau^{n+1}-X_\tau^n}{\tau}=-\grad E(X_\tau^{n+1})
\end{eqnarray*}
\end{bem}

Nach Aufstellen der Diskretisierung wollen wir $\tau \to 0$ gehen lassen und betrachten den Grenzwert, den "'generalisierten Gradientenfluss"'.
Um zu zeigen, dass dieser Grenzwert exisitert und die Ausgangsgleichung erfüllt, müssen dessen Eigenschaften untersucht werden. 

\subsection{Drei Ungleichungen}
Wir nehmen an, dass $E$ nach unten durch eine absolute Konstante ist, d.h. $E(X)\geq C$ unabh. von $X$.
\newline


$X_\tau^{n+1}$ ist ein Minimierer von dem Funktional $X \mapsto E(X)+\dfrac{\dist(X_\tau^n,X)^2}{2\tau}$, und damit ist offensichtlich das Funktional an $X_\tau^{n+1}$ kleiner gleich dem Wert dessen an der Stelle $X_\tau^n$ (Eigenschaften Metrik: $\dist(X_\tau^n,X_\tau^n)=0$). Damit haben wir
\begin{eqnarray}
E(X_\tau^{n+1})+\dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}\leq E(X_\tau^n). \label{ineq1}
\end{eqnarray} 
\begin{lem}[Energy estimate]
\begin{eqnarray}
\sup_{n\geq 0}E(X_\tau^n)\leq E(X^0) \label{enest}
\end{eqnarray}
\end{lem}
\begin{proof}
Folgt sofort aus (\ref{ineq1}), da der zweite Term nichtnegativ und somit die Folge der $(E(X_\tau^n)$ für n monoton abnehmend ist. 
\end{proof}

\begin{lem}[total square distance estimate]
\begin{eqnarray}
\sum_{n\geq 0}\dist(X_\tau^n,X_\tau^{n+1})^2\leq 2\tau (E(X^0)-\inf E)\label{totalsquare}
\end{eqnarray}
\end{lem}
\begin{proof}
Summation über (\ref{ineq1})
\end{proof}

\begin{bem}
Daraus kann auch eine Hölder 1/2-Abschätzung für $X_\tau$ abgeleitet werden: für $s<t$ gilt:
\begin{eqnarray}
\dist(X_\tau(s),X_\tau(t))^2 \leq \left[\dfrac{t-s}{\tau}+1\right] \sum_{\frac{s}{\tau}\leq n \leq \frac{t}{\tau}} \dist (X^n_\tau, X_\tau^{n+1})^2 \leq C[(t-s)+\tau], \label{Hölder}
\end{eqnarray}
wobei $C=2[E(X^0)-\inf E]$.
\\ 
Folgt aus Dreiecksunglichung für $W_2$ und Cauchy-Schwarz.
\end{bem}
 
\begin{lem}[Energy gradient estimate]
Sei eine zugrundeliegende Riemannstruktur gegeben und das Energie Funktional hinreichend glatt. Dann gilt 
\begin{eqnarray}
\tau \sum_{n\geq 0} \Vert\grad E(X_\tau^n)\Vert^2 \leq 2[E(X^0)-\inf E]
\end{eqnarray}
bzw. im kontinuierlichen Falle:
\begin{eqnarray}
\int_0^\infty \Vert\grad E(X_\tau^n)\Vert^2 dt\leq 2[E(X^0)-\inf E]
\label{Engrad}
\end{eqnarray}
\end{lem}
\begin{proof}
Sei $\omega$ ein beliebiger Tangentenvektor auf $X_\tau^{n+1}$. Definiere für ein kleines $\varepsilon>0$ einen "'Pfad"' $\tilde{X}_\varepsilon$ folgendermaßen:\\
\begin{eqnarray}
\tilde{X}_0=X_\tau^{n+1},~~\dfrac{d\tilde{X}_\varepsilon}{d\varepsilon}\Bigg|_{\varepsilon=0} =\omega
\end{eqnarray}
Da $X_\tau^{n+1}$ Minimierer ist, gilt offensichtlich
\begin{eqnarray}
E(X_\tau^{n+1})+\dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}\leq E(\tilde{X}_\varepsilon)+\dfrac{\dist(X_\tau^n,\tilde{X}_\varepsilon)^2}{2\tau}~~~\forall \varepsilon>0 \label{a)}
\end{eqnarray}
Unter der Annahme, dass das Energiefunktional glatt ist, gilt:
\begin{eqnarray}
E(\tilde{X}_\varepsilon)=E(X_\tau^{n+1})+\varepsilon\langle \grad E(X_\tau^{n+1}),\omega\rangle+O(\varepsilon^2) \label{b)}
\end{eqnarray}
Außerdem gilt:
\begin{align*}
\dist (X_\tau^n,\tilde{X}_\varepsilon)^2-\dist(X_\tau^n,X_\tau^{n+1})^2\\
=\left(\dist(X_\tau^n,\tilde{X}_\varepsilon)+\dist(X_\tau^n,X_\tau^{n+1})\right)\left(\dist(X_\tau^n,\tilde{X}_\varepsilon)-\dist(X_\tau^n,X_\tau^{n+1})\right)\\
\leq \left(\dist(X_\tau^n,\tilde{X}_\varepsilon)+\dist(X_\tau^n,X_\tau^{n+1})\right)\dist(X_\tau^{n+1},\tilde{X}_\varepsilon) \\
\leq\left(2\dist(X_\tau^n,X_\tau^{n+1}+\dist(X_\tau^{n+1},\tilde{X}_\varepsilon)\right)\dist(X_\tau^{n+1},\tilde{X}_\varepsilon)
\end{align*}
Wir wissen, dass \[\dist(X_\tau^{n+1},\tilde{X}_\varepsilon)=\varepsilon\Vert \omega \Vert + o(\varepsilon) \].
Damit wird aus obiger Gleichung
\begin{eqnarray}
\dfrac{\dist(X_\tau^n,\tilde{X}_\varepsilon)^2}{2\tau}\leq \dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}+\varepsilon\dist(X_\tau^n,X_\tau^{n+1})\dfrac{\Vert \omega \Vert}{\tau} + o(\varepsilon) \label{c)}
\end{eqnarray}
\\
Jetzt kombinieren wir die drei Aussagen \ref{a)}\ref{b)}\ref{c)}: Dazu setzen wir zunächst \ref{b)}in \ref{a)}ein.
\begin{align*}
E(X_\tau^{n+1})+\dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}\leq E(X_\tau^{n+1})+\varepsilon\langle \grad E(X_\tau^{n+1}),\omega\rangle+O(\varepsilon^2)+\dfrac{\dist(X_\tau^n,\tilde{X}_\varepsilon)^2}{2\tau}
\\
\Rightarrow \dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}\overset{\ref{c)}}{\leq} \varepsilon\langle \grad E(X_\tau^{n+1}),\omega\rangle+O(\varepsilon^2)+ \dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{2\tau}+\varepsilon\dist(X_\tau^n,X_\tau^{n+1})\dfrac{\Vert \omega \Vert}{\tau} + o(\varepsilon)\\
\Rightarrow 0\leq \varepsilon \left(\langle \grad E(X_\tau^{n+1}),\omega\rangle)+\dist(X_\tau^n,X_\tau^{n+1})\dfrac{\Vert \omega \Vert}{\tau} +\underset{\to 0 \text{ für } \varepsilon \to 0} {\underbrace{\dfrac{o(\varepsilon)}{\varepsilon}+\dfrac{O(\varepsilon^2)}{\varepsilon}}} \right)
\end{align*}
Nun wählen wir das explizite $\omega=-\grad E(X_\tau^{n+1})$ (warum ist das im geforderten raum?)
\begin{align*}
0\leq \underset{-\Vert \grad E(X_\tau^{n+1}) \Vert^2}{\underbrace{\langle \grad E(X_\tau^{n+1}),-\grad E(X_\tau^{n+1}\rangle)}}+\dfrac{\dist(X_\tau^n,X_\tau^{n+1})\Vert \grad E(X_\tau^{n+1}) \Vert}{\tau}\\
\Rightarrow \dfrac{\dist(X_\tau^n,X_\tau^{n+1})^2}{\tau^2} \geq \Vert \grad E(X_\tau^{n+1}) \Vert^2
\end{align*}
In Verbindung mit der square distance estimate (\ref{totalsquare}) kommen wir schließlich zu der geforderten Gleichung:
\begin{equation}
 2\tau (E(X^0)-\inf E)\geq \sum_{n\geq 0} \dist(X_\tau^n,X_\tau^{n+1})^2 \geq \tau^2 \sum_{n\geq 1} \Vert \grad E(X_\tau^n)\Vert^2
\end{equation}
TODO: warum kann ich den term für n=0 auch mitnehmen? also summe über $n\geq 0$?
\end{proof}
\begin{bem}
Die kontinueriliche Funktion gilt sogar in einer nicht-Riemanschen Situation mit einer passenden Definition der Norm des Gradienten. (todo: riemann setting häh?) 
\end{bem}

Diese drei Abschätzungen sollten die relative Kompaktheit von $(X_\tau)$ für $\tau \to 0$ sicherstellen. \\
Um aber zum Limes überzugehen, müssen wir ein dem letzten Beweis ähnliches Prozedere unterlaufen: Kleine perturbationen, $\omega$ beliebig lassen. Eine approximierte euler-lagrange-gl finden. siehe nächstes kapteil. außerdem: ???? 
\section{Anwendung auf das Monge-Kantorovich Problem}
Die oben erwähnte Strategie wurde zum ersten mal am Beispiel der linearen Fokker-Plank-Gleichung angewandt. Dies liefert interessante EInblicke in die Methode. Die übrigens auch implementiert werden kann. 
\begin{eqnarray}
x
\end{eqnarray}

\end{document}
